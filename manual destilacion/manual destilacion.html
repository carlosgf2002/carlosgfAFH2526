<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Informe Técnico: Destilación de Conocimiento</title>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@600;800&family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #3b82f6; /* Blue 500 */
            --secondary-color: #1d4ed8; /* Blue 700 */
            --bg-body: #f8fafc;
            --bg-card: #ffffff;
            --text-main: #334155;
            --text-muted: #64748b;
            --border-color: #e2e8f0;
            --code-bg: #0f172a;
            --code-text: #e2e8f0;
            --success-bg: #dcfce7;
            --success-text: #166534;
            --error-bg: #fee2e2;
            --error-text: #991b1b;
            --warning-bg: #ffedd5;
            --warning-text: #9a3412;
        }

        body {
            font-family: 'Roboto', sans-serif;
            background-color: var(--bg-body);
            color: var(--text-main);
            line-height: 1.8;
            margin: 0;
            padding: 40px 20px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background: var(--bg-card);
            padding: 50px;
            border-radius: 16px;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
        }

        header {
            border-bottom: 2px solid var(--border-color);
            padding-bottom: 30px;
            margin-bottom: 40px;
        }

        h1 { 
            font-family: 'Montserrat', sans-serif;
            color: var(--secondary-color); 
            font-size: 2.2rem;
            margin-bottom: 10px;
            letter-spacing: -0.5px;
        }
        
        .author {
            font-weight: 500;
            color: var(--text-muted);
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 15px;
        }

        .hardware-badge {
            display: inline-block;
            background-color: #f1f5f9;
            color: var(--text-main);
            padding: 6px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: 600;
            border: 1px solid var(--border-color);
        }

        h2 { 
            font-family: 'Montserrat', sans-serif;
            color: var(--secondary-color); 
            font-size: 1.5rem;
            margin-top: 50px;
            margin-bottom: 25px;
            display: flex;
            align-items: center;
        }
        
        h2::before {
            content: '';
            display: inline-block;
            width: 8px;
            height: 28px;
            background-color: var(--primary-color);
            margin-right: 15px;
            border-radius: 4px;
        }

        h3 {
            color: var(--text-main);
            font-weight: 700;
            margin-top: 25px;
        }

        .card {
            background-color: #fff;
            border: 1px solid var(--border-color);
            border-radius: 12px;
            padding: 25px;
            margin-bottom: 25px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.02);
        }

        code {
            font-family: 'Fira Code', 'Consolas', monospace;
            background-color: #f1f5f9;
            color: #d946ef;
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 0.9em;
        }

        pre {
            background-color: var(--code-bg);
            color: var(--code-text);
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85em;
            border-left: 5px solid var(--primary-color);
            margin: 15px 0;
        }

        /* Technical Log Styling */
        .log-entry {
            border: 1px solid var(--border-color);
            border-radius: 8px;
            margin-bottom: 15px;
            overflow: hidden;
        }

        .log-header {
            padding: 10px 15px;
            background-color: #f8fafc;
            border-bottom: 1px solid var(--border-color);
            font-weight: 600;
            font-size: 0.9em;
        }

        .log-header.error { color: var(--error-text); background-color: var(--error-bg); }
        .log-header.success { color: var(--success-text); background-color: var(--success-bg); }

        .log-body { padding: 15px; font-size: 0.95em; }

        /* Metrics Grid */
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }

        .metric-card {
            background: linear-gradient(135deg, #eff6ff 0%, #ffffff 100%);
            border: 1px solid #bfdbfe;
            padding: 20px;
            border-radius: 12px;
            text-align: center;
        }

        .metric-val {
            font-size: 2.5rem;
            font-weight: 800;
            color: var(--primary-color);
            display: block;
            line-height: 1;
            margin-bottom: 5px;
        }

        .metric-lbl {
            font-size: 0.8em;
            text-transform: uppercase;
            letter-spacing: 1px;
            color: var(--text-muted);
            font-weight: 600;
        }

        /* Images */
        .figure {
            margin-top: 20px;
            border: 1px solid var(--border-color);
            border-radius: 8px;
            overflow: hidden;
            background: #fafafa;
        }

        img {
            width: 100%;
            height: auto;
            display: block;
        }

        .figcaption {
            padding: 10px;
            text-align: center;
            font-size: 0.85em;
            color: var(--text-muted);
            background: #f8fafc;
            border-top: 1px solid var(--border-color);
            font-style: italic;
        }

        footer {
            text-align: center;
            margin-top: 60px;
            padding-top: 20px;
            border-top: 1px solid var(--border-color);
            font-size: 0.85em;
            color: var(--text-muted);
        }
    </style>
</head>
<body>

<div class="container">
    <header>
        <h1>Compresión de Modelos: Destilación de Conocimiento</h1>
        <div class="author">Desarrollado por: Carlos González Fernández</div>
        <div class="hardware-badge">Hardware: Mac mini (Apple Silicon M-Series / MPS)</div>
    </header>

    <section>
        <h2>1. Definición del Proyecto</h2>
        <p>El objetivo de esta práctica es implementar una técnica de compresión de modelos conocida como <strong>Knowledge Distillation</strong> (Destilación de Conocimiento). Se busca transferir las capacidades de generalización de un modelo masivo ("Teacher") a una arquitectura compacta y eficiente ("Student") apta para despliegue en edge devices.</p>
        
        
        <div class="card">
            <h3>Arquitectura Seleccionada</h3>
            <ul>
                <li><strong>Modelo Maestro (Teacher):</strong> DistilBERT (66 Millones de parámetros).</li>
                <li><strong>Modelo Estudiante (Student):</strong> BERT-Tiny (4 Millones de parámetros).</li>
                <li><strong>Objetivo:</strong> Minimizar la divergencia KL entre las distribuciones de salida de ambos modelos.</li>
            </ul>
        </div>
    </section>

    <section>
        <h2>2. Configuración del Entorno (Apple Silicon)</h2>
        <p>Para habilitar la aceleración por hardware en macOS, se configuró el backend <strong>MPS (Metal Performance Shaders)</strong> en lugar de CUDA. Esto permite utilizar la GPU integrada del chip M-Series.</p>
        
        <pre><code># Creación del entorno virtual aislado
python3 -m venv venv
source venv/bin/activate

# Instalación de dependencias con soporte Metal
pip install torch torchvision transformers datasets accelerate</code></pre>
    </section>

    <section>
        <h2>3. Desafíos de Ingeniería</h2>
        <p>Durante la implementación del script <code>destilar.py</code>, se encontraron y resolvieron las siguientes excepciones críticas:</p>

        <div class="log-entry">
            <div class="log-header error">Fallo: Incompatibilidad en Argumentos de Pérdida</div>
            <div class="log-body">
                <code>TypeError: compute_loss() got an unexpected keyword argument...</code><br>
                <strong>Solución:</strong> Se refactorizó la firma del método <code>compute_loss</code> añadiendo <code>**kwargs</code> para garantizar compatibilidad con las versiones recientes de la librería <em>Trainer</em> de Hugging Face.
            </div>
        </div>

        <div class="log-entry">
            <div class="log-header error">Fallo: Discrepancia en Tokenizadores</div>
            <div class="log-body">
                <code>TypeError: forward() got an unexpected keyword argument 'token_type_ids'</code><br>
                <strong>Solución:</strong> El modelo maestro (DistilBERT) no acepta <code>token_type_ids</code>, un parámetro generado por el tokenizador del estudiante. Se implementó un filtro de diccionario en el paso <em>forward</em>.
            </div>
        </div>
    </section>

    <section>
        <h2>4. Métricas de Rendimiento</h2>
        <p>Tras la ejecución del entrenamiento (3 épocas) utilizando la aceleración MPS, se obtuvieron los siguientes resultados:</p>

        <div class="metrics-grid">
            <div class="metric-card">
                <span class="metric-val">15.3x</span>
                <span class="metric-lbl">Factor de Compresión</span>
            </div>
            <div class="metric-card">
                <span class="metric-val">80.6%</span>
                <span class="metric-lbl">Precisión Final</span>
            </div>
            <div class="metric-card">
                <span class="metric-val">~18 min</span>
                <span class="metric-lbl">Tiempo de Entrenamiento</span>
            </div>
        </div>

        <div class="figure">
            <img src="img/prueba2.png" alt="Consola de resultados">
            <div class="figcaption">Fig 1. Validación final: Reducción de 66M a 4.39M parámetros.</div>
        </div>
        
        <div class="figure">
            <img src="img/prueba1.png" alt="Proceso de entrenamiento">
            <div class="figcaption">Fig 2. Log de entrenamiento mostrando la convergencia de la función de pérdida.</div>
        </div>
    </section>

    <section>
        <h2>5. Análisis Comparativo de Inferencia</h2>
        <p>Se sometió a ambos modelos a un test cualitativo para evaluar la pérdida semántica.</p>

        <div class="card">
            <h3>Resultados del Test de Estrés</h3>
            <ul>
                <li><strong>✅ Detección de Sarcasmo:</strong> El modelo estudiante logró identificar correctamente la ironía en frases complejas ("Great... flat tire"), heredando esta capacidad del maestro.</li>
                <li><strong>✅ Sesgos Cognitivos:</strong> Se observó que el estudiante mimetiza los sesgos lógicos del modelo original (ej. fallos en dobles negaciones).</li>
                <li><strong>⚠️ Limitación de Atención:</strong> Debido a la reducción de capas de atención (Self-Attention heads), el modelo estudiante muestra degradación en el análisis de oraciones largas con sentimientos mixtos.</li>
            </ul>
        </div>
        
        <div class="figure">
            <img src="img/prueba4.png" alt="Tabla comparativa">
            <div class="figcaption">Fig 3. Matriz de confusión cualitativa: Maestro vs. Estudiante.</div>
        </div>
    </section>

    <footer>
        <p>© 2024 Carlos González Fernández | Documentación de IA Avanzada</p>
    </footer>
</div>

</body>
</html>