<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Informe Técnico: Cuantización de Modelos</title>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@600;800&family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #0ea5e9; /* Sky Blue */
            --secondary-color: #0369a1;
            --bg-body: #f8fafc;
            --bg-card: #ffffff;
            --text-main: #334155;
            --text-muted: #64748b;
            --border-color: #e2e8f0;
            --code-bg: #1e293b;
            --code-text: #e2e8f0;
            --highlight-metric: #0ea5e9;
            --metric-bg: #f0f9ff;
        }

        body {
            font-family: 'Roboto', sans-serif;
            background-color: var(--bg-body);
            color: var(--text-main);
            line-height: 1.8;
            margin: 0;
            padding: 40px 20px;
        }

        .container {
            max-width: 850px;
            margin: 0 auto;
            background: var(--bg-card);
            padding: 50px;
            border-radius: 16px;
            box-shadow: 0 10px 25px rgba(0,0,0,0.05);
        }

        header {
            text-align: left;
            padding-bottom: 30px;
            border-bottom: 2px solid var(--border-color);
            margin-bottom: 40px;
        }

        h1 { 
            font-family: 'Montserrat', sans-serif;
            color: var(--secondary-color); 
            font-size: 2.2rem;
            margin-bottom: 10px;
            letter-spacing: -0.5px;
        }
        
        .author {
            font-weight: 500;
            color: var(--text-muted);
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 15px;
        }

        h2 { 
            font-family: 'Montserrat', sans-serif;
            color: var(--secondary-color); 
            font-size: 1.4rem;
            margin-top: 40px;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
        }
        
        h2::before {
            content: '';
            display: inline-block;
            width: 6px;
            height: 24px;
            background-color: var(--primary-color);
            margin-right: 12px;
            border-radius: 3px;
        }

        h3 { 
            color: var(--text-main); 
            font-weight: 700;
            font-size: 1.1rem;
            margin-top: 25px;
        }

        .tags {
            display: flex;
            gap: 10px;
        }

        .tag {
            background-color: var(--metric-bg);
            color: var(--secondary-color);
            padding: 5px 12px;
            border-radius: 6px;
            font-size: 0.8em;
            font-weight: 600;
            border: 1px solid #bae6fd;
        }

        .card {
            background-color: #fff;
            border: 1px solid var(--border-color);
            border-radius: 12px;
            padding: 25px;
            margin-bottom: 25px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.02);
        }

        .step-list {
            list-style: none;
            padding: 0;
        }
        
        .step-list li {
            margin-bottom: 15px;
            padding-left: 20px;
            border-left: 2px solid var(--border-color);
        }

        .step-list strong {
            color: var(--secondary-color);
        }

        code {
            font-family: 'Fira Code', 'Consolas', monospace;
            background-color: #f1f5f9;
            color: #d946ef;
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 0.9em;
        }

        pre {
            background-color: var(--code-bg);
            color: var(--code-text);
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85em;
            border-left: 5px solid var(--primary-color);
            margin-top: 10px;
        }

        .metrics-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 25px;
        }

        .metric-box {
            background: var(--metric-bg);
            padding: 20px;
            border-radius: 10px;
            text-align: center;
            border: 1px solid #bae6fd;
        }

        .metric-value {
            font-size: 1.8rem;
            font-weight: 800;
            color: var(--secondary-color);
            display: block;
            margin-top: 5px;
        }

        .metric-label {
            font-size: 0.85em;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .alert-warning {
            background-color: #fff7ed;
            border-left: 4px solid #f97316;
            color: #9a3412;
            padding: 15px;
            border-radius: 6px;
            font-size: 0.95em;
            margin-top: 20px;
        }

        .figure {
            margin-top: 25px;
            border: 1px solid var(--border-color);
            border-radius: 8px;
            overflow: hidden;
            background: #fafafa;
        }

        img {
            width: 100%;
            height: auto;
            display: block;
        }

        .figcaption {
            padding: 12px;
            text-align: center;
            font-size: 0.85em;
            color: var(--text-muted);
            background: #f8fafc;
            border-top: 1px solid var(--border-color);
        }

        footer {
            text-align: center;
            margin-top: 60px;
            padding-top: 20px;
            border-top: 1px solid var(--border-color);
            font-size: 0.85em;
            color: var(--text-muted);
        }
    </style>
</head>
<body>

<div class="container">
    <header>
        <h1>Optimización de LLMs: Cuantización</h1>
        <div class="author">Desarrollado por: Carlos González Fernández</div>
        <div class="tags">
            <span class="tag">#MLX</span>
            <span class="tag">#LlamaCPP</span>
            <span class="tag">#GGUF</span>
            <span class="tag">#AppleSilicon</span>
        </div>
    </header>

    <section>
        <h2>1. Entorno de Desarrollo y Pre-requisitos</h2>
        <p>Para garantizar la reproducibilidad del proceso, se parte de la infraestructura configurada en la fase de entrenamiento (Fine-Tuning). El objetivo es optimizar el modelo fusionado (merged) para su ejecución eficiente en hardware de consumo.</p>
        
        <div class="card">
            <h3>Flujo de Preparación</h3>
            <ul class="step-list">
                <li>
                    <strong>Inicialización de Entorno:</strong> Activación del entorno virtual Python y carga de librerías MLX.
                    <pre><code>source venv/bin/activate
pip install mlx-lm cmake</code></pre>
                </li>
                <li>
                    <strong>Compilación del Motor:</strong> Construcción de <code>llama.cpp</code> con flags específicos para aceleración Metal (GPU).
                    <pre><code>cd llama.cpp
cmake -B build
cmake --build build --config Release -j</code></pre>
                </li>
                <li>
                    <strong>Fusión de Adaptadores (LoRA):</strong> Consolidación de los pesos base (Phi-3) con los adaptadores entrenados.
                    <pre><code>python -m mlx_lm.fuse --model microsoft/Phi-3-mini-4k-instruct --adapter-path adapters --save-path merged_model</code></pre>
                </li>
            </ul>
        </div>
    </section>

    <section>
        <h2>2. Protocolo de Cuantización</h2>
        <p>El proceso de cuantización reduce la precisión de los pesos del modelo para disminuir el consumo de VRAM y el almacenamiento en disco. Se ha seleccionado el formato <strong>GGUF</strong> y el esquema de cuantización <strong>Q4_K_M</strong> (4-bits).</p>

        <div class="card">
            <h3>Paso A: Estandarización a FP16</h3>
            <p>Conversión del modelo fusionado a formato GGUF en precisión media (Half-Precision).</p>
            <pre><code>python llama.cpp/convert_hf_to_gguf.py merged_model --outfile chef-bot-f16.gguf</code></pre>

            <h3>Paso B: Compresión a 4-Bits</h3>
            <p>Ejecución del algoritmo de cuantización final.</p>
            <pre><code>./llama.cpp/build/bin/llama-quantize chef-bot-f16.gguf chef-bot-q4.gguf q4_k_m</code></pre>
        </div>
    </section>

    <section>
        <h2>3. Análisis de Rendimiento</h2>
        <p>A continuación se detallan las métricas comparativas entre el modelo original (FP16) y la versión optimizada (Q4).</p>
        
        <div class="metrics-grid">
            <div class="metric-box">
                <span class="metric-label">Modelo Original (FP16)</span>
                <span class="metric-value" style="color: #ef4444;">~7.12 GB</span>
            </div>
            <div class="metric-box">
                <span class="metric-label">Modelo Optimizado (Q4)</span>
                <span class="metric-value" style="color: #22c55e;">~2.23 GB</span>
            </div>
        </div>

        <div class="figure">
            <img src="cuantizacion.jpg" alt="Evidencia de consola">
            <div class="figcaption">Fig 1. Log de ejecución mostrando la reducción de tamaño en disco.</div>
        </div>

        <div class="alert-warning">
            <strong>⚠️ Observación sobre Inferencia:</strong> 
            Se ha detectado un "Trade-off" (compromiso) en el rendimiento. Aunque el tamaño en disco se ha reducido drásticamente, la velocidad de generación de texto <strong>(tokens/segundo)</strong> ha disminuido en más de un 50% en comparación con el modelo original. Esto debe considerarse para aplicaciones que requieran baja latencia.
        </div>
    </section>

    <footer>
        <p>© 2024 Carlos González Fernández | Ingeniería de IA Local</p>
    </footer>
</div>

</body>
</html>